{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Practice Exercise: Scikit-Learn 1\n",
    "## Basic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Objectives\n",
    "\n",
    "In line with the [SK1 Tutorial](https://www.featureranking.com/tutorials/machine-learning-tutorials/sk-part-1-basic-modeling/), the objective of this practice notebook is to familiarize you with working with a regression problem using a `holdout` approach. The dataset under consideration is the `diamonds` dataset that comes with the `ggplot2` library in R.\n",
    "\n",
    "The `diamonds` dataset contains information on diamonds including carat (numeric), clarity (categorical), cut (categorical), and color (categorical). The dataset has 10 features and 53940 instances. The objective is to predict the price of a diamond in USD given its attributes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise 0: Data Preparation\n",
    "\n",
    "Prepare the dataset for predictive modeling as follows:\n",
    "\n",
    "0. Refer to our data prep practice solutions on Canvas as well as our data prep script on GitHub [here](https://github.com/akmand/datasets/blob/master/prepare_dataset_for_modeling.py) for some inspiration on preparing this data for predictive modeling.\n",
    "1. Set `pd.set_option('display.max_columns', None)`. Read in the raw data `diamonds.csv` on GitHub [here](https://github.com/akmand/datasets). Have a look at the shape and data types of the features. Also have a look at the top 5 rows.\n",
    "2. Generate descriptive statistics for categorical and numerical features separately.\n",
    "3. Have a look at the unique values for each categorical feature and check whether everything is OK in the sense that there are no unusual values.\n",
    "4. Make sure there are no missing values anywhere.\n",
    "5. Separate the last column from the dataset and set it to \"target\". Make sure \"target\" is a `Pandas` series at this point, and not a `NumPy` array (which will be necessary for the sampling below). Set all the other columns to be the \"Data\" data frame, which will be the set of descriptive features.\n",
    "6. Make sure all categorical descriptive features are encoded via one-hot-encoding. In this particular dataset, some categorical descriptive features are actually ordinal, but we will go ahead and encode them via one-hot-encoding for simplicity.\n",
    "7. Make sure all descriptive features are scaled via min-max scaling and the output is a `Pandas` data frame with correct column names. Do **NOT** scale the target feature!\n",
    "8. Finally have a look at the top 5 rows of \"target\" and \"Data\" respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53940, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table     x     y     z  price\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0  3.95  3.98  2.43    326\n",
       "1   0.21  Premium     E     SI1   59.8   61.0  3.89  3.84  2.31    326\n",
       "2   0.23     Good     E     VS1   56.9   65.0  4.05  4.07  2.31    327\n",
       "3   0.29  Premium     I     VS2   62.4   58.0  4.20  4.23  2.63    334\n",
       "4   0.31     Good     J     SI2   63.3   58.0  4.34  4.35  2.75    335"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "\n",
    "# so that we can see all the columns\n",
    "pd.set_option('display.max_columns', None) \n",
    "\n",
    "df_url = 'https://raw.githubusercontent.com/akmand/datasets/master/diamonds.csv'\n",
    "url_content = requests.get(df_url, verify=False).content\n",
    "df = pd.read_csv(io.StringIO(url_content.decode('utf-8')))\n",
    "\n",
    "# df = pd.read_csv('diamonds.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carat      float64\n",
       "cut         object\n",
       "color       object\n",
       "clarity     object\n",
       "depth      float64\n",
       "table      float64\n",
       "x          float64\n",
       "y          float64\n",
       "z          float64\n",
       "price        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53940.000</td>\n",
       "      <td>53940.000</td>\n",
       "      <td>53940.000</td>\n",
       "      <td>53940.000</td>\n",
       "      <td>53940.000</td>\n",
       "      <td>53940.000</td>\n",
       "      <td>53940.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.798</td>\n",
       "      <td>61.749</td>\n",
       "      <td>57.457</td>\n",
       "      <td>5.731</td>\n",
       "      <td>5.735</td>\n",
       "      <td>3.539</td>\n",
       "      <td>3932.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.474</td>\n",
       "      <td>1.433</td>\n",
       "      <td>2.234</td>\n",
       "      <td>1.122</td>\n",
       "      <td>1.142</td>\n",
       "      <td>0.706</td>\n",
       "      <td>3989.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200</td>\n",
       "      <td>43.000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>326.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.400</td>\n",
       "      <td>61.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>4.710</td>\n",
       "      <td>4.720</td>\n",
       "      <td>2.910</td>\n",
       "      <td>950.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.700</td>\n",
       "      <td>61.800</td>\n",
       "      <td>57.000</td>\n",
       "      <td>5.700</td>\n",
       "      <td>5.710</td>\n",
       "      <td>3.530</td>\n",
       "      <td>2401.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.040</td>\n",
       "      <td>62.500</td>\n",
       "      <td>59.000</td>\n",
       "      <td>6.540</td>\n",
       "      <td>6.540</td>\n",
       "      <td>4.040</td>\n",
       "      <td>5324.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.010</td>\n",
       "      <td>79.000</td>\n",
       "      <td>95.000</td>\n",
       "      <td>10.740</td>\n",
       "      <td>58.900</td>\n",
       "      <td>31.800</td>\n",
       "      <td>18823.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           carat      depth      table          x          y          z  \\\n",
       "count  53940.000  53940.000  53940.000  53940.000  53940.000  53940.000   \n",
       "mean       0.798     61.749     57.457      5.731      5.735      3.539   \n",
       "std        0.474      1.433      2.234      1.122      1.142      0.706   \n",
       "min        0.200     43.000     43.000      0.000      0.000      0.000   \n",
       "25%        0.400     61.000     56.000      4.710      4.720      2.910   \n",
       "50%        0.700     61.800     57.000      5.700      5.710      3.530   \n",
       "75%        1.040     62.500     59.000      6.540      6.540      4.040   \n",
       "max        5.010     79.000     95.000     10.740     58.900     31.800   \n",
       "\n",
       "          price  \n",
       "count  53940.00  \n",
       "mean    3932.80  \n",
       "std     3989.44  \n",
       "min      326.00  \n",
       "25%      950.00  \n",
       "50%     2401.00  \n",
       "75%     5324.25  \n",
       "max    18823.00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=np.number).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53940</td>\n",
       "      <td>53940</td>\n",
       "      <td>53940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>SI1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>21551</td>\n",
       "      <td>11292</td>\n",
       "      <td>13065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cut  color clarity\n",
       "count   53940  53940   53940\n",
       "unique      5      7       8\n",
       "top     Ideal      G     SI1\n",
       "freq    21551  11292   13065"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=np.object).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column cut:\n",
      "Ideal        21551\n",
      "Premium      13791\n",
      "Very Good    12082\n",
      "Good          4906\n",
      "Fair          1610\n",
      "Name: cut, dtype: int64 \n",
      "\n",
      "Column color:\n",
      "G    11292\n",
      "E     9797\n",
      "F     9542\n",
      "H     8304\n",
      "D     6775\n",
      "I     5422\n",
      "J     2808\n",
      "Name: color, dtype: int64 \n",
      "\n",
      "Column clarity:\n",
      "SI1     13065\n",
      "VS2     12258\n",
      "SI2      9194\n",
      "VS1      8171\n",
      "VVS2     5066\n",
      "VVS1     3655\n",
      "IF       1790\n",
      "I1        741\n",
      "Name: clarity, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's ensure the categorical features look OK\n",
    "\n",
    "# get the list of categorical descriptive features\n",
    "categorical_cols = df.columns[df.dtypes==np.object].tolist()\n",
    "\n",
    "for categorical_col in categorical_cols:\n",
    "    print('Column ' + categorical_col + ':')\n",
    "    print(df[categorical_col].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carat      0\n",
       "cut        0\n",
       "color      0\n",
       "clarity    0\n",
       "depth      0\n",
       "table      0\n",
       "x          0\n",
       "y          0\n",
       "z          0\n",
       "price      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's make sure there are no missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "#### Data Preparation\n",
    "###############################\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# last column is target feature\n",
    "target = df.iloc[:, -1]\n",
    "\n",
    "# everything else is Data, i.e., the set of descriptive features\n",
    "Data = df.iloc[:, :-1]\n",
    "\n",
    "# if a nominal feature has only 2 levels:\n",
    "# encode it as a single binary variable\n",
    "for col in categorical_cols:\n",
    "    n = len(Data[col].unique())\n",
    "    if n == 2:\n",
    "        Data[col] = pd.get_dummies(Data[col], drop_first=True)\n",
    "\n",
    "# for categorical features with >2 levels: use one-hot-encoding\n",
    "Data = pd.get_dummies(Data)\n",
    "Data_cols = Data.columns\n",
    "\n",
    "# scale Data between 0 and 1\n",
    "# set the output to a data frame with correct column names\n",
    "Data = pd.DataFrame(preprocessing.MinMaxScaler().fit_transform(Data), \n",
    "                    columns=Data_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53940, 26)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>cut_Fair</th>\n",
       "      <th>cut_Good</th>\n",
       "      <th>cut_Ideal</th>\n",
       "      <th>cut_Premium</th>\n",
       "      <th>cut_Very Good</th>\n",
       "      <th>color_D</th>\n",
       "      <th>color_E</th>\n",
       "      <th>color_F</th>\n",
       "      <th>color_G</th>\n",
       "      <th>color_H</th>\n",
       "      <th>color_I</th>\n",
       "      <th>color_J</th>\n",
       "      <th>clarity_I1</th>\n",
       "      <th>clarity_IF</th>\n",
       "      <th>clarity_SI1</th>\n",
       "      <th>clarity_SI2</th>\n",
       "      <th>clarity_VS1</th>\n",
       "      <th>clarity_VS2</th>\n",
       "      <th>clarity_VVS1</th>\n",
       "      <th>clarity_VVS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006237</td>\n",
       "      <td>0.513889</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.367784</td>\n",
       "      <td>0.067572</td>\n",
       "      <td>0.076415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.362197</td>\n",
       "      <td>0.065195</td>\n",
       "      <td>0.072642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006237</td>\n",
       "      <td>0.386111</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.377095</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.072642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.018711</td>\n",
       "      <td>0.538889</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.391061</td>\n",
       "      <td>0.071817</td>\n",
       "      <td>0.082704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022869</td>\n",
       "      <td>0.563889</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.404097</td>\n",
       "      <td>0.073854</td>\n",
       "      <td>0.086478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      carat     depth     table         x         y         z  cut_Fair  \\\n",
       "0  0.006237  0.513889  0.230769  0.367784  0.067572  0.076415       0.0   \n",
       "1  0.002079  0.466667  0.346154  0.362197  0.065195  0.072642       0.0   \n",
       "2  0.006237  0.386111  0.423077  0.377095  0.069100  0.072642       0.0   \n",
       "3  0.018711  0.538889  0.288462  0.391061  0.071817  0.082704       0.0   \n",
       "4  0.022869  0.563889  0.288462  0.404097  0.073854  0.086478       0.0   \n",
       "\n",
       "   cut_Good  cut_Ideal  cut_Premium  cut_Very Good  color_D  color_E  color_F  \\\n",
       "0       0.0        1.0          0.0            0.0      0.0      1.0      0.0   \n",
       "1       0.0        0.0          1.0            0.0      0.0      1.0      0.0   \n",
       "2       1.0        0.0          0.0            0.0      0.0      1.0      0.0   \n",
       "3       0.0        0.0          1.0            0.0      0.0      0.0      0.0   \n",
       "4       1.0        0.0          0.0            0.0      0.0      0.0      0.0   \n",
       "\n",
       "   color_G  color_H  color_I  color_J  clarity_I1  clarity_IF  clarity_SI1  \\\n",
       "0      0.0      0.0      0.0      0.0         0.0         0.0          0.0   \n",
       "1      0.0      0.0      0.0      0.0         0.0         0.0          1.0   \n",
       "2      0.0      0.0      0.0      0.0         0.0         0.0          0.0   \n",
       "3      0.0      0.0      1.0      0.0         0.0         0.0          0.0   \n",
       "4      0.0      0.0      0.0      1.0         0.0         0.0          0.0   \n",
       "\n",
       "   clarity_SI2  clarity_VS1  clarity_VS2  clarity_VVS1  clarity_VVS2  \n",
       "0          1.0          0.0          0.0           0.0           0.0  \n",
       "1          0.0          0.0          0.0           0.0           0.0  \n",
       "2          0.0          1.0          0.0           0.0           0.0  \n",
       "3          0.0          0.0          1.0           0.0           0.0  \n",
       "4          1.0          0.0          0.0           0.0           0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53940,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    326\n",
       "1    326\n",
       "2    327\n",
       "3    334\n",
       "4    335\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise 1: Modeling Preparation\n",
    "\n",
    "- Randomly sample 5000 rows as it's too big for a short demo (using a random seed of 999). Make sure to run `reset_index(drop=True)` on the sampled data to reset the indices.\n",
    "> - **NOTE:** It's **extremely** important to use the same seed for both Data and target while sampling, otherwise you will happily mix and match different rows without getting any execution errors and all you results will be garbage.\n",
    "- Split the sampled data as 70% training set and the remaining 30% test set using a random seed of 999. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 26)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_sample = Data.sample(n=5000, random_state=999).reset_index(drop=True)\n",
    "Data_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_sample = target.sample(n=5000, random_state=999).reset_index(drop=True)\n",
    "target_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "D_train, D_test, t_train, t_test = train_test_split(Data_sample.values, \n",
    "                                                    target_sample.values, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500, 26)\n",
      "(1500, 26)\n",
      "(3500,)\n",
      "(1500,)\n"
     ]
    }
   ],
   "source": [
    "print(D_train.shape)\n",
    "print(D_test.shape)\n",
    "print(t_train.shape)\n",
    "print(t_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "- Fit a nearest neighbor (NN) regressor with $k=3$ neighbors using the Euclidean distance. \n",
    "- Fit the model on the train data and evaluate its $R^2$ (the default \"score()\" for regressors) performance on the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_knn: 0.83\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=3, p=2)\n",
    "knn_regressor.fit(D_train, t_train)\n",
    "\n",
    "score_knn = knn_regressor.score(D_test, t_test)\n",
    "\n",
    "print(f'score_knn: {score_knn:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "- Extend Question 2 by fitting $k=1,\\ldots,10$ neighbors using the Manhattan and Euclidean distances respectively.\n",
    "- What is the optimal $k$ value for each distance metric? That is, at which $k$, the NN regressor returns the highest $R^2$ score?\n",
    "- Which distance metric seems to be better? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = list(np.arange(1, 11))\n",
    "\n",
    "knn_score_manhattan = []\n",
    "knn_score_euclidean = []\n",
    "\n",
    "for k in k_list:\n",
    "    knn_regressor_manhattan = KNeighborsRegressor(n_neighbors=k, p=1)\n",
    "    knn_regressor_manhattan.fit(D_train, t_train)\n",
    "    knn_score_manhattan = knn_score_manhattan + [knn_regressor_manhattan.score(D_test, t_test)]\n",
    "    \n",
    "    knn_regressor_euclidean = KNeighborsRegressor(n_neighbors=k, p=2)\n",
    "    knn_regressor_euclidean.fit(D_train, t_train)\n",
    "    knn_score_euclidean = knn_score_euclidean + [knn_regressor_euclidean.score(D_test, t_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_manhattan</th>\n",
       "      <th>score_euclidean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.835761</td>\n",
       "      <td>0.834437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.840516</td>\n",
       "      <td>0.834388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.830256</td>\n",
       "      <td>0.827770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.809021</td>\n",
       "      <td>0.805942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.784022</td>\n",
       "      <td>0.781398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.750180</td>\n",
       "      <td>0.751187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.725849</td>\n",
       "      <td>0.727718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.706174</td>\n",
       "      <td>0.705348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.690405</td>\n",
       "      <td>0.690273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.676477</td>\n",
       "      <td>0.675774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    score_manhattan  score_euclidean\n",
       "1          0.835761         0.834437\n",
       "2          0.840516         0.834388\n",
       "3          0.830256         0.827770\n",
       "4          0.809021         0.805942\n",
       "5          0.784022         0.781398\n",
       "6          0.750180         0.751187\n",
       "7          0.725849         0.727718\n",
       "8          0.706174         0.705348\n",
       "9          0.690405         0.690273\n",
       "10         0.676477         0.675774"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'score_manhattan': knn_score_manhattan, \n",
    "                        'score_euclidean': knn_score_euclidean},\n",
    "                      index = k_list)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "- Fit a decision tree regressor with default values on the train data, and then evaluate its performance on the test data. \n",
    "- Does it perform better than the best KNN model from the previous question?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9463271975470922"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt_regressor = DecisionTreeRegressor() # max_depth=5)\n",
    "dt_regressor.fit(D_train, t_train)\n",
    "dt_regressor.score(D_test, t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "- Fit a simple linear regression model on train data, and then evaluate its performance on the test data. **Hint:** Use `LinearRegression()` in `sklearn.linear_model`. \n",
    "- How does it compare to the previous models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9335004777674455"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_regressor = LinearRegression()\n",
    "linear_regressor.fit(D_train, t_train)\n",
    "linear_regressor.score(D_test, t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "- Fit a random forest regressor with `n_estimators=100` on train data, and then evaluate its performance on the test data. \n",
    "- How does it compare to the previous models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9674201153178088"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100)\n",
    "rf_regressor.fit(D_train, t_train)\n",
    "rf_regressor.score(D_test, t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "- Predict the first 5 observations of the **test** data using the linear regression model you built earlier. \n",
    "- Display your results as a data frame with three columns: 'target', 'prediction', 'absolute_diff'.\n",
    "- How do the predictions look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "      <th>absolute_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2919</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>1129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>912</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2365</td>\n",
       "      <td>2144.0</td>\n",
       "      <td>221.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11666</td>\n",
       "      <td>10536.0</td>\n",
       "      <td>1130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1881</td>\n",
       "      <td>2328.0</td>\n",
       "      <td>447.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  prediction  absolute_diff\n",
       "0    2919      4048.0         1129.0\n",
       "1     912      1072.0          160.0\n",
       "2    2365      2144.0          221.0\n",
       "3   11666     10536.0         1130.0\n",
       "4    1881      2328.0          447.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_obs = D_test[0:5]\n",
    "\n",
    "preds = linear_regressor.predict(new_obs)\n",
    "\n",
    "results = pd.DataFrame({'target': t_test[0:5], \n",
    "                        'prediction':preds})\n",
    "\n",
    "results['absolute_diff'] = np.abs(results['target'] - results['prediction'])\n",
    "results.round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Further exposition**\n",
    "\n",
    "Let's create histograms to visualize the difference between predicted values from the linear regression and target values on both training and test sets. How are the difference values distributed? Are they centered around zero? What are minimum and maximum difference values for training and test sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 1.000e+00, 0.000e+00,\n",
       "        3.000e+00, 2.000e+00, 7.000e+00, 3.000e+00, 1.600e+01, 3.100e+01,\n",
       "        2.900e+01, 5.300e+01, 1.130e+02, 2.230e+02, 4.820e+02, 9.860e+02,\n",
       "        1.111e+03, 3.220e+02, 5.700e+01, 2.900e+01, 1.400e+01, 4.000e+00,\n",
       "        2.000e+00, 1.000e+00, 1.000e+00, 4.000e+00, 2.000e+00, 1.000e+00]),\n",
       " array([-10231.        ,  -9647.03333333,  -9063.06666667,  -8479.1       ,\n",
       "         -7895.13333333,  -7311.16666667,  -6727.2       ,  -6143.23333333,\n",
       "         -5559.26666667,  -4975.3       ,  -4391.33333333,  -3807.36666667,\n",
       "         -3223.4       ,  -2639.43333333,  -2055.46666667,  -1471.5       ,\n",
       "          -887.53333333,   -303.56666667,    280.4       ,    864.36666667,\n",
       "          1448.33333333,   2032.3       ,   2616.26666667,   3200.23333333,\n",
       "          3784.2       ,   4368.16666667,   4952.13333333,   5536.1       ,\n",
       "          6120.06666667,   6704.03333333,   7288.        ]),\n",
       " <BarContainer object of 30 artists>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "pred_train = linear_regressor.predict(D_train)\n",
    "pred_test = linear_regressor.predict(D_test)\n",
    "diff_train = pred_train - t_train\n",
    "diff_test = pred_test - t_test\n",
    "plt.hist(diff_train, bins=30)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2.,   2.,   1.,   3.,   3.,   6.,   6.,  17.,   9.,  21.,  35.,\n",
       "         64., 123., 170., 291., 360., 263.,  73.,  21.,  13.,   4.,   6.,\n",
       "          2.,   1.,   1.,   1.,   1.,   0.,   0.,   1.]),\n",
       " array([-5993.        , -5583.03333333, -5173.06666667, -4763.1       ,\n",
       "        -4353.13333333, -3943.16666667, -3533.2       , -3123.23333333,\n",
       "        -2713.26666667, -2303.3       , -1893.33333333, -1483.36666667,\n",
       "        -1073.4       ,  -663.43333333,  -253.46666667,   156.5       ,\n",
       "          566.46666667,   976.43333333,  1386.4       ,  1796.36666667,\n",
       "         2206.33333333,  2616.3       ,  3026.26666667,  3436.23333333,\n",
       "         3846.2       ,  4256.16666667,  4666.13333333,  5076.1       ,\n",
       "         5486.06666667,  5896.03333333,  6306.        ]),\n",
       " <BarContainer object of 30 artists>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(diff_test, bins=30) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Exercise 8\n",
    "\n",
    "This question requires basic knowledge of linear regression:\n",
    "- Compute the previous predictions directly *without* using the `fit()` function. \n",
    "\n",
    "**Background:** Using the textbook notation, a linear regression model is defined as:\n",
    "\n",
    "$$\\mathbb{M}_w(d) = w[0] + \\sum_{j=1}^{p} w[j] \\times d[j]$$\n",
    "\n",
    "where \n",
    "- $d$ is a vector of descriptive features, \n",
    "- $w[0]$ is the intercept, and\n",
    "- $w[1], w[2],\\ldots,w[p]$ are the regression weights corresponding to these features. \n",
    "\n",
    "Here, the target feature (the price of a diamond) can be modeled as a weighted linear combination of descriptive features. We shall not cover linear regression in depth. If you are interested, please refer to Sections 7.2 and 7.3 in the textbook for more details.\n",
    "\n",
    "**Hint:** \n",
    "1. Use the `coef_` attribute of the `linear_regressor` object to get the regression coefficients. \n",
    "2. Multiply `new_obs` with the regression coefficients, perform sum along `axis=1`.\n",
    "3. Use the `intercept_` attribute to get the constant term in the linear regression and add it to the above sum. \n",
    "4. Confirm that your results are the same as in the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11018711, 0.525     , 0.23076923, 0.54283054, 0.09796265,\n",
       "        0.11289308, 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.04158004, 0.55277778, 0.23076923, 0.43947858, 0.0803056 ,\n",
       "        0.09339623, 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.10602911, 0.53055556, 0.21153846, 0.53351955, 0.09779287,\n",
       "        0.11226415, 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.27234927, 0.49722222, 0.34615385, 0.68156425, 0.12393888,\n",
       "        0.13993711, 0.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.11434511, 0.46666667, 0.32692308, 0.55493482, 0.10050934,\n",
       "        0.11163522, 0.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.62343079e+04, -3.41979334e+03, -1.01033882e+03, -2.57254453e+04,\n",
       "        6.60065814e+04,  5.11834428e+03, -1.73312746e+15, -1.73312746e+15,\n",
       "       -1.73312746e+15, -1.73312746e+15, -1.73312746e+15,  3.89097868e+16,\n",
       "        3.89097868e+16,  3.89097868e+16,  3.89097868e+16,  3.89097868e+16,\n",
       "        3.89097868e+16,  3.89097868e+16,  1.76639830e+16,  1.76639830e+16,\n",
       "        1.76639830e+16,  1.76639830e+16,  1.76639830e+16,  1.76639830e+16,\n",
       "        1.76639830e+16,  1.76639830e+16])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regressor.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.484064237005433e+16"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regressor.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4056.,  1080.,  2160., 10544.,  2312.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = (new_obs*linear_regressor.coef_).sum(axis=1) + linear_regressor.intercept_\n",
    "predictions.round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Regression Diagnostics\n",
    "\n",
    "Relying on $R^{2}$ to evaluate regressor performance is not sufficient. Sometimes, we need to ensure if the regressors generate reasonable predictions. In this case, we have to check if the predicted diamond prices are positive (a negative price would imply you would get the diamond free and some extra cash!) \n",
    "\n",
    "Let's predict on training set for each model developed in the previous exercises. Create a dataframe, named `pred_result`, which consists of four columns corresponding to their predictions. Then, run `pred_result.describe()` to check if any model has a negative minimum value. Does the result surprise you? Will you get a similar result if you predict on test set?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=2, p=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to fit the optimal KNN based on the result in Exercise 3\n",
    "KNN_optimal = KNeighborsRegressor(n_neighbors=2, p=1)\n",
    "KNN_optimal.fit(D_train, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>DecisionTree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3500.000000</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>3500.000000</td>\n",
       "      <td>3500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3984.761857</td>\n",
       "      <td>4028.560920</td>\n",
       "      <td>4026.221714</td>\n",
       "      <td>4022.388000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3915.514521</td>\n",
       "      <td>4009.765666</td>\n",
       "      <td>3897.362852</td>\n",
       "      <td>4058.232226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>375.500000</td>\n",
       "      <td>383.490000</td>\n",
       "      <td>-3496.000000</td>\n",
       "      <td>342.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>963.000000</td>\n",
       "      <td>943.902500</td>\n",
       "      <td>1048.000000</td>\n",
       "      <td>953.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2531.750000</td>\n",
       "      <td>2547.455000</td>\n",
       "      <td>2876.000000</td>\n",
       "      <td>2490.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5432.625000</td>\n",
       "      <td>5451.545000</td>\n",
       "      <td>6040.000000</td>\n",
       "      <td>5438.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18614.000000</td>\n",
       "      <td>17966.220000</td>\n",
       "      <td>21032.000000</td>\n",
       "      <td>18781.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                KNN  RandomForest  LinearRegression  DecisionTree\n",
       "count   3500.000000   3500.000000       3500.000000   3500.000000\n",
       "mean    3984.761857   4028.560920       4026.221714   4022.388000\n",
       "std     3915.514521   4009.765666       3897.362852   4058.232226\n",
       "min      375.500000    383.490000      -3496.000000    342.000000\n",
       "25%      963.000000    943.902500       1048.000000    953.500000\n",
       "50%     2531.750000   2547.455000       2876.000000   2490.500000\n",
       "75%     5432.625000   5451.545000       6040.000000   5438.000000\n",
       "max    18614.000000  17966.220000      21032.000000  18781.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_knn_train = KNN_optimal.predict(D_train)\n",
    "pred_rf_train = rf_regressor.predict(D_train)\n",
    "pred_lr_train = linear_regressor.predict(D_train)\n",
    "pred_dt_train = dt_regressor.predict(D_train)\n",
    "\n",
    "pred_results = pd.DataFrame({\"KNN\": pred_knn_train,\n",
    "                             \"RandomForest\":  pred_rf_train,\n",
    "                             \"LinearRegression\": pred_lr_train,\n",
    "                             \"DecisionTree\": pred_dt_train})\n",
    "pred_results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "www.featureranking.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
